{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a80c8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index\n",
      "  Downloading llama_index-0.4.35.post1.tar.gz (149 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.2/149.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting dataclasses_json\n",
      "  Downloading dataclasses_json-0.5.7-py3-none-any.whl (25 kB)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.0.120-py3-none-any.whl (424 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m424.0/424.0 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/valeskaalves/opt/anaconda3/lib/python3.9/site-packages (from llama-index) (1.21.5)\n",
      "Collecting tenacity<9.0.0,>=8.2.0\n",
      "  Downloading tenacity-8.2.2-py3-none-any.whl (24 kB)\n",
      "Collecting openai>=0.26.4\n",
      "  Downloading openai-0.27.2-py3-none-any.whl (70 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in /Users/valeskaalves/opt/anaconda3/lib/python3.9/site-packages (from llama-index) (1.4.4)\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.3.2-cp39-cp39-macosx_10_9_x86_64.whl (735 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m735.2/735.2 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.20 in /Users/valeskaalves/opt/anaconda3/lib/python3.9/site-packages (from openai>=0.26.4->llama-index) (2.28.1)\n",
      "Requirement already satisfied: tqdm in /Users/valeskaalves/opt/anaconda3/lib/python3.9/site-packages (from openai>=0.26.4->llama-index) (4.64.1)\n",
      "Requirement already satisfied: aiohttp in /Users/valeskaalves/opt/anaconda3/lib/python3.9/site-packages (from openai>=0.26.4->llama-index) (3.8.3)\n",
      "Collecting marshmallow-enum<2.0.0,>=1.5.1\n",
      "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Collecting typing-inspect>=0.4.0\n",
      "  Downloading typing_inspect-0.8.0-py3-none-any.whl (8.7 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.3.0\n",
      "  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.4.1 in /Users/valeskaalves/opt/anaconda3/lib/python3.9/site-packages (from langchain->llama-index) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<2,>=1 in /Users/valeskaalves/opt/anaconda3/lib/python3.9/site-packages (from langchain->llama-index) (1.4.39)\n",
      "Collecting pydantic<2,>=1\n",
      "  Downloading pydantic-1.10.7-cp39-cp39-macosx_10_9_x86_64.whl (2.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /Users/valeskaalves/opt/anaconda3/lib/python3.9/site-packages (from pandas->llama-index) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/valeskaalves/opt/anaconda3/lib/python3.9/site-packages (from pandas->llama-index) (2022.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/valeskaalves/opt/anaconda3/lib/python3.9/site-packages (from tiktoken->llama-index) (2022.7.9)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/valeskaalves/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->openai>=0.26.4->llama-index) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/valeskaalves/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->openai>=0.26.4->llama-index) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /Users/valeskaalves/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->openai>=0.26.4->llama-index) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/valeskaalves/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->openai>=0.26.4->llama-index) (6.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/valeskaalves/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->openai>=0.26.4->llama-index) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/valeskaalves/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->openai>=0.26.4->llama-index) (1.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/valeskaalves/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->openai>=0.26.4->llama-index) (1.8.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/valeskaalves/opt/anaconda3/lib/python3.9/site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses_json->llama-index) (21.3)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/valeskaalves/opt/anaconda3/lib/python3.9/site-packages (from pydantic<2,>=1->langchain->llama-index) (4.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/valeskaalves/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->llama-index) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/valeskaalves/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.20->openai>=0.26.4->llama-index) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/valeskaalves/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.20->openai>=0.26.4->llama-index) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/valeskaalves/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.20->openai>=0.26.4->llama-index) (2022.9.24)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/valeskaalves/opt/anaconda3/lib/python3.9/site-packages (from SQLAlchemy<2,>=1->langchain->llama-index) (2.0.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/valeskaalves/opt/anaconda3/lib/python3.9/site-packages (from typing-inspect>=0.4.0->dataclasses_json->llama-index) (0.4.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/valeskaalves/opt/anaconda3/lib/python3.9/site-packages (from packaging>=17.0->marshmallow<4.0.0,>=3.3.0->dataclasses_json->llama-index) (3.0.9)\n",
      "Building wheels for collected packages: llama-index\n",
      "  Building wheel for llama-index (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for llama-index: filename=llama_index-0.4.35.post1-py3-none-any.whl size=222437 sha256=3c8cb5353fb6c111c0ab83f377e997f0e5d37f445b2e610aaad89299d3fbef87\n",
      "  Stored in directory: /Users/valeskaalves/Library/Caches/pip/wheels/b5/a6/e1/097a2cb045cfd5bd9021ee72e190c7cfa79f2a0beea46fc4c1\n",
      "Successfully built llama-index\n",
      "Installing collected packages: typing-inspect, tenacity, pydantic, tiktoken, marshmallow, openai, marshmallow-enum, dataclasses_json, langchain, llama-index\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 8.0.1\n",
      "    Uninstalling tenacity-8.0.1:\n",
      "      Successfully uninstalled tenacity-8.0.1\n",
      "Successfully installed dataclasses_json-0.5.7 langchain-0.0.120 llama-index-0.4.35.post1 marshmallow-3.19.0 marshmallow-enum-1.5.1 openai-0.27.2 pydantic-1.10.7 tenacity-8.2.2 tiktoken-0.3.2 typing-inspect-0.8.0\n",
      "Requirement already satisfied: langchain in /Users/valeskaalves/opt/anaconda3/lib/python3.9/site-packages (0.0.120)\n",
      "Requirement already satisfied: SQLAlchemy<2,>=1 in /Users/valeskaalves/opt/anaconda3/lib/python3.9/site-packages (from langchain) (1.4.39)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/valeskaalves/opt/anaconda3/lib/python3.9/site-packages (from langchain) (2.28.1)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/valeskaalves/opt/anaconda3/lib/python3.9/site-packages (from langchain) (1.21.5)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /Users/valeskaalves/opt/anaconda3/lib/python3.9/site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/valeskaalves/opt/anaconda3/lib/python3.9/site-packages (from langchain) (3.8.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/valeskaalves/opt/anaconda3/lib/python3.9/site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /Users/valeskaalves/opt/anaconda3/lib/python3.9/site-packages (from langchain) (0.5.7)\n",
      "Requirement already satisfied: pydantic<2,>=1 in /Users/valeskaalves/opt/anaconda3/lib/python3.9/site-packages (from langchain) (1.10.7)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/valeskaalves/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/valeskaalves/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/valeskaalves/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/valeskaalves/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /Users/valeskaalves/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/valeskaalves/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/valeskaalves/opt/anaconda3/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /Users/valeskaalves/opt/anaconda3/lib/python3.9/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /Users/valeskaalves/opt/anaconda3/lib/python3.9/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.8.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /Users/valeskaalves/opt/anaconda3/lib/python3.9/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/valeskaalves/opt/anaconda3/lib/python3.9/site-packages (from pydantic<2,>=1->langchain) (4.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/valeskaalves/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2->langchain) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/valeskaalves/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/valeskaalves/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2->langchain) (1.26.13)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/valeskaalves/opt/anaconda3/lib/python3.9/site-packages (from SQLAlchemy<2,>=1->langchain) (2.0.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/valeskaalves/opt/anaconda3/lib/python3.9/site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (21.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/valeskaalves/opt/anaconda3/lib/python3.9/site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (0.4.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/valeskaalves/opt/anaconda3/lib/python3.9/site-packages (from packaging>=17.0->marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (3.0.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index\n",
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5910537a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import SimpleDirectoryReader, GPTListIndex, readers, GPTSimpleVectorIndex, LLMPredictor, PromptHelper\n",
    "from langchain import OpenAI\n",
    "import sys\n",
    "import os\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "def construct_index(directory_path):\n",
    "    # set maximum input size\n",
    "    max_input_size = 4096\n",
    "    # set number of output tokens\n",
    "    num_outputs = 2000\n",
    "    # set maximum chunk overlap\n",
    "    max_chunk_overlap = 20\n",
    "    # set chunk size limit\n",
    "    chunk_size_limit = 600 \n",
    "\n",
    "    # define LLM\n",
    "    llm_predictor = LLMPredictor(llm=OpenAI(temperature=0.5, model_name=\"text-davinci-003\", max_tokens=num_outputs))\n",
    "    prompt_helper = PromptHelper(max_input_size, num_outputs, max_chunk_overlap, chunk_size_limit=chunk_size_limit)\n",
    " \n",
    "    documents = SimpleDirectoryReader(directory_path).load_data()\n",
    "    \n",
    "    index = GPTSimpleVectorIndex(\n",
    "        documents, llm_predictor=llm_predictor, prompt_helper=prompt_helper\n",
    "    )\n",
    "\n",
    "    index.save_to_disk('index.json')\n",
    "\n",
    "    return index\n",
    "\n",
    "def ask_ai():\n",
    "    index = GPTSimpleVectorIndex.load_from_disk('index.json')\n",
    "    while True: \n",
    "        query = input(\"What do you want to ask? \")\n",
    "        response = index.query(query, response_mode=\"compact\")\n",
    "        display(Markdown(f\"Response: <b>{response.response}</b>\"))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04f30c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paste your OpenAI key here and hit enter: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\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = input(\"Paste your OpenAI key here and hit enter:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6760df2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_documents] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [build_index_from_documents] Total embedding token usage: 3802 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<llama_index.indices.vector_store.vector_indices.GPTSimpleVectorIndex at 0x7fe1d001b490>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "construct_index(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98153568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What do you want to ask? What is the main ingredient for the lunch?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 573 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 9 tokens\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Response: <b>\n",
       "The main ingredient for lunch is not specified in the context information.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What do you want to ask? How much time is needed to prepare a lunch?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [query] Total LLM token usage: 609 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [query] Total embedding token usage: 10 tokens\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Response: <b>\n",
       "It depends on the type of lunch being prepared. Some lunches can be prepared quickly, while others may require more time. For example, a sandwich or salad can be prepared in a few minutes, while a more complex dish like lasagna may take longer.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/dq/jx6zt2hd4lx90cd8_tbzmqs00000gn/T/ipykernel_59619/3873586889.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mask_ai\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/dq/jx6zt2hd4lx90cd8_tbzmqs00000gn/T/ipykernel_59619/3839299127.py\u001b[0m in \u001b[0;36mask_ai\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPTSimpleVectorIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'index.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"What do you want to ask? \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"compact\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMarkdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Response: <b>{response.response}</b>\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "ask_ai()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3e8bd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
